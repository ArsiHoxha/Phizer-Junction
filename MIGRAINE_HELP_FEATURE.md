# ğŸ¤ Migraine Help Voice Assistant Feature

## Overview
This feature provides real-time voice-based assistance for users experiencing migraines. It uses **Speech-to-Text** (Whisper AI) and **Text-to-Speech** (ElevenLabs) to create a conversational experience where users can describe their symptoms and receive immediate AI-powered guidance.

---

## ğŸ¯ User Flow

### 1. **Accessing the Feature**
- From the main dashboard, users can tap the **"Need Help"** button (red button with medical icon)
- This opens the Migraine Help screen

### 2. **Voice Interaction**
1. **User taps the microphone button** â†’ Recording starts
2. **User describes symptoms** â†’ "I have a severe headache on my left side with nausea"
3. **User taps to stop** â†’ Audio is transcribed using OpenAI Whisper
4. **AI processes the message** â†’ Gemini AI analyzes symptoms with user's health context
5. **AI responds via voice** â†’ ElevenLabs converts response to natural speech
6. **Conversation continues** â†’ Users can ask follow-up questions

### 3. **Quick Actions**
Users can also tap quick-action buttons for common scenarios:
- "I have a headache"
- "I feel nauseous"
- "Light sensitivity"
- "What should I do?"

---

## ğŸ—ï¸ Technical Architecture

### **Frontend** (`client/app/migraine-help.tsx`)

#### Components:
- **Voice Recording**: Uses `expo-av` to record user's voice
- **Conversation Display**: Chat-style interface showing user and AI messages
- **Quick Actions**: Preset buttons for common queries
- **Visual Feedback**: Shows recording, processing, and speaking states

#### Key Functions:

```typescript
startRecording()    // Captures user voice input
stopRecording()     // Stops recording and sends to backend
transcribeAudio()   // Converts speech to text via backend
getAIResponse()     // Gets intelligent response from Gemini AI
speakText()         // Converts AI response to speech via ElevenLabs
```

#### States:
- `isRecording` - Voice is being captured
- `isProcessing` - Audio is being transcribed and analyzed
- `isSpeaking` - AI response is being spoken
- `conversation` - Array of all messages exchanged

---

### **Backend** (`backend/server.js`)

#### New API Endpoints:

##### 1. **POST `/api/ai/transcribe-elevenlabs`**
Converts recorded audio to text using ElevenLabs Speech-to-Text

**Input:**
- `audio` (file): Audio recording (m4a/wav/mp3)

**Output:**
```json
{
  "text": "I have a severe headache with light sensitivity"
}
```

**How it works:**
1. Receives audio file via multipart/form-data
2. Forwards to ElevenLabs Speech-to-Text API
3. Uses `eleven_multilingual_v2` model for high accuracy
4. Returns transcribed text

**Why ElevenLabs instead of Whisper?**
- âœ… Same provider for both speech-to-text AND text-to-speech
- âœ… No need for OpenAI account
- âœ… Better integration with voice responses
- âœ… More generous free tier

---

##### 2. **POST `/api/ai/migraine-help`**
Provides AI-powered migraine assistance

**Input:**
```json
{
  "message": "I have a severe headache",
  "conversationHistory": [
    { "role": "user", "content": "Previous message..." },
    { "role": "assistant", "content": "Previous response..." }
  ]
}
```

**Output:**
```json
{
  "response": "I understand you're in pain. Try resting in a dark, quiet room. If you have prescribed medication, now is a good time to take it. Stay hydrated with small sips of water."
}
```

**Context Provided to AI:**
- User's current health metrics (HRV, stress, sleep, screen time) with interpretation
- Recent migraine history (last 3 migraines with triggers)
- Conversation history (last 4 messages for context)

**AI Prompt Structure:**
```
You are a compassionate migraine care assistant...

User's Current Health Data:
- HRV: 45ms (LOW - nervous system stressed)
- Stress: 75% (HIGH)
- Sleep: 5.2 hours (Poor - sleep deprivation)
- Recent migraines: 3 in past week, common triggers: stress, poor sleep

Conversation:
User: I have a severe headache
Assistant: [2-3 sentence empathetic, practical response]
```

**Gemini 2.0 Flash Configuration:**
- Temperature: 0.9 (More creative, empathetic responses)
- TopP: 0.95 (Diverse vocabulary)
- Max tokens: 150 (Keep responses concise)

---

## ğŸ™ï¸ Integration Details

### **1. ElevenLabs Speech-to-Text**
- **API**: `https://api.elevenlabs.io/v1/speech-to-text`
- **Model**: `eleven_multilingual_v2`
- **Accuracy**: ~95% for clear speech in multiple languages
- **Cost**: Free tier includes 10,000 characters/month
- **Benefits**: Single provider for both speech-to-text AND text-to-speech

**Setup:**
```bash
# Already configured in backend/.env âœ…
ELEVENLABS_API_KEY=sk_46e01cad85b2f7f1e2c8570535befc8e23be2411dc5c11e0
```

---

### **2. ElevenLabs Text-to-Speech**
- **API**: `https://api.elevenlabs.io/v1/text-to-speech/{voice_id}`
- **Voice**: Sarah (empathetic, caring tone)
- **Voice ID**: `EXAVITQu4vr4xnSDxMaL`
- **Cost**: Same free tier as speech-to-text
- **Quality**: Natural, human-like speech with emotion

**Already configured in both:**
- âœ… Backend: `.env` file
- âœ… Frontend: `migraine-help.tsx`

---

### **3. Google Gemini 2.0 Flash Exp (Conversational AI)**
- **Model**: `gemini-2.0-flash-exp` (Latest experimental model)
- **Purpose**: Generates empathetic, contextual responses
- **Config**: Temperature 0.9, TopP 0.95, Max 150 tokens
- **Cost**: Free tier available
- **Already configured** âœ…

**Why Gemini 2.0 Flash?**
- âš¡ Faster responses than GPT-4
- ğŸ’° More cost-effective
- ğŸ¯ Excellent at empathetic healthcare conversations
- ğŸ”„ Better context retention
- ğŸ†“ Generous free tier

---

## ğŸ“± User Experience Features

### **Visual Indicators:**
- ğŸ”´ **Recording**: Red pulsing button with "Listening..." text
- âš™ï¸ **Processing**: Loading spinner with "Processing..." text
- ğŸ”Š **Speaking**: Volume icon with "Speaking..." text
- âœ… **Ready**: Blue microphone button with "Tap to Speak"

### **Conversation Bubbles:**
- **User messages**: Blue bubbles on the right with person icon
- **AI messages**: White/dark bubbles on the left with medical icon
- **Timestamps**: Shows time of each message

### **Quick Actions:**
- ğŸ’Š Medical - "I have a headache"
- âš ï¸ Warning - "I feel nauseous"
- â˜€ï¸ Sunny - "Light sensitivity"
- â“ Help - "What should I do?"

---

## ğŸ”’ Security & Privacy

### **Authentication:**
- All API calls require valid Clerk JWT token
- User-specific context is fetched securely

### **Data Handling:**
- Audio files are **not stored** on server
- Transcriptions are processed in real-time
- Conversation history is client-side only

### **Privacy Considerations:**
- Audio processing happens via secure HTTPS
- No conversation data is saved to database
- User health metrics used only for context

---

## ğŸš€ Setup Instructions

### **1. Backend Setup**

```bash
cd backend

# Install dependencies
npm install multer form-data

# Verify .env has ElevenLabs key (already configured âœ…)
cat .env | grep ELEVENLABS
# Should show: ELEVENLABS_API_KEY=sk_46e01cad85b2f7f1e2c8570535befc8e23be2411dc5c11e0

# Restart server
npm start
```

### **2. Frontend Setup**

```bash
cd client

# The ElevenLabs API key is already configured in migraine-help.tsx âœ…
# No additional packages needed (expo-av already installed)
```

### **3. API Key Verification**

#### **ElevenLabs (Speech-to-Text + Text-to-Speech):**
âœ… Already configured in:
- Backend: `.env` file
- Frontend: `migraine-help.tsx`

If you need a new key:
1. Go to https://elevenlabs.io/
2. Sign up (free tier: 10,000 characters/month)
3. Profile â†’ API Key â†’ Copy
4. Update both backend `.env` and frontend file

#### **Gemini AI:**
âœ… Already configured in backend `.env`

---

## ğŸ’¡ Usage Examples

### **Example Conversation:**

**User:** ğŸ¤ "I'm getting a migraine. Left side of my head is throbbing."

**AI:** ğŸ”Š "I'm sorry you're experiencing pain. Based on your recent stress levels being high at 75%, this might be stress-related. Try these steps:

1. Move to a dark, quiet room
2. Apply a cold compress to the painful area
3. Take your prescribed medication if available
4. Practice slow, deep breathing

Your HRV is also low at 45ms, so relaxation is key. Would you like more specific relief techniques?"

**User:** ğŸ¤ "Yes, what breathing exercises can help?"

**AI:** ğŸ”Š "Try the 4-7-8 technique:
1. Breathe in for 4 seconds
2. Hold for 7 seconds
3. Exhale for 8 seconds
4. Repeat 4 times

This activates your parasympathetic nervous system and can reduce migraine intensity. How are you feeling now?"

---

## ğŸ“Š Benefits

### **For Users:**
- âœ… Hands-free assistance during migraine episodes
- âœ… Immediate, contextual guidance
- âœ… Reduces anxiety through empathetic AI
- âœ… No need to type when in pain
- âœ… Natural conversation flow

### **For App:**
- âœ… Differentiating feature from competitors
- âœ… Increases user engagement
- âœ… Provides value during critical moments
- âœ… Builds trust through supportive AI
- âœ… Collects usage patterns (anonymously)

---

## ğŸ¨ UI Components

### **Main Screen Layout:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â† Migraine Help                â”‚  Header
â”‚     Voice Assistant              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                  â”‚
â”‚  ğŸ’Š Hello! I'm your migraine    â”‚  AI Message
â”‚     assistant...                 â”‚
â”‚     10:30 AM                     â”‚
â”‚                                  â”‚
â”‚                     I have a  ğŸ‘¤ â”‚  User Message
â”‚                     headache.    â”‚
â”‚                     10:31 AM     â”‚
â”‚                                  â”‚
â”‚  ğŸ’Š I understand...              â”‚  AI Response
â”‚     [empathetic response]        â”‚
â”‚     10:31 AM                     â”‚
â”‚                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [ğŸ’Š] I have   [âš ï¸] I feel        â”‚  Quick Actions
â”‚  a headache      nauseous        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                  â”‚
â”‚    ğŸ¤ Tap to Speak               â”‚  Voice Button
â”‚                                  â”‚
â”‚  Press and hold to describe...   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› Error Handling

### **Microphone Permission Denied:**
```typescript
// Shows alert asking user to enable mic in settings
alert('Please grant microphone permissions...');
```

### **Transcription Fails:**
```typescript
// Returns fallback message
return 'I couldn\'t hear that clearly. Could you try again?';
```

### **AI API Error:**
```typescript
// Provides supportive fallback response
'I understand you\'re going through a difficult time. 
Try resting in a dark, quiet room and staying hydrated.'
```

### **Network Issues:**
```typescript
// Queues message for retry
// Shows offline indicator
```

---

## ğŸ“ˆ Future Enhancements

### **Phase 2:**
- [ ] Save conversation history to database
- [ ] Emergency contact integration ("Call my doctor")
- [ ] Medication reminder integration
- [ ] Multi-language support
- [ ] Offline mode with pre-recorded responses

### **Phase 3:**
- [ ] Video call with healthcare provider
- [ ] Share conversation with doctor
- [ ] Voice-activated migraine logging
- [ ] Ambient sound therapy integration
- [ ] Real-time symptom tracking during conversation

---

## ğŸ“ Testing Checklist

- [ ] Record voice â†’ transcription accurate
- [ ] AI response is empathetic and relevant
- [ ] TTS plays correctly
- [ ] Quick actions work
- [ ] Conversation history displays
- [ ] Works in dark mode
- [ ] Handles interruptions (phone call, app background)
- [ ] Permissions handled gracefully
- [ ] Error states show helpful messages

---

## ğŸ†˜ Troubleshooting

### **Audio Not Recording:**
1. Check microphone permissions in device settings
2. Verify `expo-av` is installed
3. Check Audio.setAudioModeAsync configuration

### **Transcription Returns Empty:**
1. Verify ELEVENLABS_API_KEY in both backend .env and frontend
2. Check audio file format (should be m4a/wav/mp3)
3. Test with longer recordings (3+ seconds)
4. Ensure clear speech without background noise

### **AI Response Slow:**
1. Check backend logs for Gemini API errors
2. Verify GEMINI_API_KEY is valid
3. Gemini 2.0 Flash should respond in 1-2 seconds
4. Consider reducing maxOutputTokens if needed

### **TTS Not Playing:**
1. Verify ELEVENLABS_API_KEY in frontend code (line 9)
2. Check base64 audio conversion
3. Test with simple text first
4. Ensure device volume is up and not muted

---

## ğŸ“š Resources

- **Expo Audio Docs**: https://docs.expo.dev/versions/latest/sdk/audio/
- **ElevenLabs Speech-to-Text**: https://elevenlabs.io/docs/api-reference/speech-to-text
- **ElevenLabs Text-to-Speech**: https://elevenlabs.io/docs/api-reference/text-to-speech
- **Gemini 2.0 Flash**: https://ai.google.dev/gemini-api/docs/models/gemini-v2

---

**Created by**: Phizer Junction Team  
**Last Updated**: November 15, 2025  
**Version**: 1.0.0
